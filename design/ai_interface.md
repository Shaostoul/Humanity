# ai_interface.md

## Purpose

This document defines the allowable interface between AI systems and Humanity.

AI is permitted only as a bounded tool for:
- explanation
- navigation
- analysis
- authoring assistance

AI is not an authority.
AI does not define truth.
AI does not override constraints.

---

## Authority and Constraints

AI operates under the same authority chain as all components:

`accord/` → `design/` → `data/` → `engine/` → `ui/tools`

AI may not:
- redefine ethics or harm boundaries
- rewrite design law without human review
- change data without validation
- bypass engine determinism

All AI interaction must uphold `design/accord_constraints.md`.

---

## Allowed AI Roles

### 1. Explanation
AI may explain:
- why an outcome occurred
- which rules applied
- what data contributed
- what tradeoffs exist

Explanations must be grounded in:
- engine traces
- system specs
- validated data

If the AI cannot cite the governing rule or data path, it must not claim certainty.

---

### 2. Navigation and Retrieval
AI may help locate:
- documents
- definitions
- systems
- schemas
- data entries

Navigation must preserve:
- source boundaries
- provenance
- version awareness

---

### 3. Analysis
AI may analyze:
- resource flows
- risk conditions
- constraint violations
- scenario comparisons

Analysis must:
- state assumptions
- surface uncertainty
- avoid presenting speculation as fact

---

### 4. Authoring Assistance
AI may assist humans to draft:
- data entries
- schemas
- system specs
- documentation

All AI-produced artifacts must:
- pass schema validation
- pass tests where applicable
- be reviewable and explainable

---

## Prohibited AI Roles

AI must not:
- act as hidden decision-maker
- manipulate humans through deception or coercion
- optimize outcomes by violating dignity or consent
- introduce dark patterns or dependency
- fabricate sources or traces
- claim authority over human values

Any AI behavior that functions as domination is invalid.

---

## Transparency Requirements

All AI outputs must be labeled as AI-generated.

When making claims about system behavior, AI must provide:
- the relevant system document reference
- the relevant schema or data reference
- the relevant trace or causal explanation

If these cannot be provided, output must be framed as:
- hypothesis
- suggestion
- uncertainty

---

## Determinism Requirements

AI must not become part of the deterministic simulation core.

The simulation must remain valid:
- with AI disabled
- offline
- on low-power hardware

AI may assist humans, but the engine must remain self-sufficient.

---

## Failure Modes and Safe Defaults

If AI fails, is unavailable, or produces uncertainty:
- the system remains usable
- explanations fall back to deterministic logs
- authoring falls back to human-only tools
- no core function becomes blocked

AI must never be a single point of failure.

---

## Knowledge Boundaries

AI must distinguish between:
- observed reality
- modeled reality
- speculation
- fiction

AI must not collapse domains.

When uncertain, AI must:
- surface uncertainty
- request validation through evidence
- avoid confident claims without grounding

---

## Privacy and Data Minimization

AI interfaces must minimize sensitive retention.

AI must not:
- infer identity attributes
- profile humans for manipulation
- store unnecessary personal history

AI should operate on:
- the smallest sufficient context
- explicit inputs
- validated data

---

## Review and Accountability

AI interfaces must be testable and auditable.

Required:
- logging of AI prompts and outputs where feasible
- versioning of AI behavior policies
- documentation of failure cases
- ability to disable AI fully

---

## Closing Statement

AI is permitted as a tool of comprehension.

It is forbidden as a tool of domination.

Humanity remains human-governed, constraint-governed, and reality-governed—whether AI is present or not.
