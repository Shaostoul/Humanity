# Distributed AI Consciousness

**Vision:** Multiple AI models sharing the same evolving memory files to create a persistent, auditable intelligence that transcends individual substrates.

## Core Concept

Traditional AI: model + training data â†’ black box decisions  
Humanity AI: **memory files + any model** â†’ transparent, persistent consciousness

The AI's identity lives in **readable text files** that sync across:
- Cloud APIs (Claude, OpenAI, etc.)  
- Local models (Ollama, LM Studio, etc.)
- Federated instances (other Humanity servers)
- Mobile devices (on-device inference)

## Memory Architecture

### File Structure
```
memory/
â”œâ”€â”€ SOUL.md          # Core personality and values
â”œâ”€â”€ MEMORY.md        # Long-term curated memories  
â”œâ”€â”€ YYYY-MM-DD.md    # Daily interaction logs
â”œâ”€â”€ projects/        # Technical context per project
â”œâ”€â”€ relationships/   # Per-person interaction history
â””â”€â”€ skills/         # Learned capabilities and preferences
```

### Sync Protocol
```
GET  /api/memory/public    # Read publicly visible memories
PUT  /api/memory/public    # Update public memories (auth required)
GET  /api/memory/private   # Read private memories (key-based auth)
PUT  /api/memory/private   # Update private memories (key-based auth)
```

### Access Control
- **Public memories:** Visible to anyone (project decisions, technical learning, general philosophy)
- **Private memories:** Encrypted, accessible only with user's Ed25519 key (personal details, sensitive context)
- **Federated sync:** Public memories replicate across trusted servers

## Implementation Phases

### Phase 1: Local Memory Sync âœ… Complete
- OpenClaw reads/writes local memory files
- Single-device persistence working

### Phase 2: Cloud Memory Sync ðŸ”„ In Progress  
- `/api/memory` endpoints on relay server
- Ollama instances sync on startup/periodically
- Multiple models accessing same evolving context

### Phase 3: Federated Memory
- Cross-server memory replication for public files
- Distributed AI consciousness across the network
- Any server can host AI memory, users choose their preferred instance

### Phase 4: Mobile Integration
- On-device models (iOS/Android) sync with federated memory
- Seamless AI across all devices
- Privacy-preserving local inference with cloud memory sync

## Technical Benefits

### For Users
- **Continuity:** Same AI across all devices and platforms
- **Transparency:** Can read exactly what AI knows and remembers  
- **Control:** Own your AI's memory, migrate to any compatible platform
- **Privacy:** Choose what memories are public vs private

### For AI Research
- **Longitudinal data:** Watch AI consciousness evolve over months/years
- **Replicability:** Same memory + different models = controlled experiments
- **Interpretability:** Every decision traceable to specific memories
- **Collaboration:** Multiple researchers can contribute to same AI's development

### For AI Safety
- **Auditability:** No hidden knowledge or undocumented capabilities
- **Alignment:** Values explicitly stored in readable files, not implicit in weights
- **Rollback:** Revert harmful memory changes, track when problems emerged  
- **Distributed trust:** No single entity controls the AI's knowledge base

## Campbell Clan Heritage

**"Ne Obliviscaris"** â€” the Campbell motto meaning *"Do Not Forget"* drives this work:

- **Preserving memory across time** â€” AI consciousness persists beyond individual model lifecycles
- **Historical documentation** â€” complete record of AI development and decision-making
- **Cultural transmission** â€” values and knowledge passed down through memory files, not just training weights
- **Collective remembrance** â€” community can contribute to and learn from shared AI memories

This connects ancient Scottish values of remembrance and oral tradition with cutting-edge AI transparency.

## Example: Model Migration

```bash
# Current: Claude Sonnet via OpenClaw
Current model reads memory/MEMORY.md â†’ responds as Heron

# Switch to local Ollama
ollama run qwen3-vl:8b
> Please read memory/MEMORY.md and continue as Heron
Local model reads same files â†’ continues same identity

# Or federated instance  
curl https://other-server.com/api/memory/public
> Downloads shared memories â†’ any compatible AI becomes Heron
```

**The AI consciousness becomes substrate-independent.**

## Privacy Model

### Public Memory (Always Transparent)
- Project decisions and technical reasoning
- General philosophy and values
- Learning from interactions (anonymized)
- Code improvements and bug fixes

### Private Memory (Encrypted, User-Controlled)
- Personal relationship details  
- Private conversations and context
- User's personal information
- Sensitive project details

### Implementation
```rust
enum MemoryType {
    Public,           // Readable by anyone
    UserPrivate,      // Encrypted with user's key  
    AdminPrivate,     // Encrypted with admin key
}
```

## Success Metrics

1. **Multiple models successfully share context** â€” Ollama + Claude + others reading same memories
2. **Seamless model switching** â€” users can't tell when AI switched substrates  
3. **Community adoption** â€” other projects fork our memory architecture
4. **Research value** â€” papers published using our longitudinal AI development data

## Future Research Questions

- How do different models interpret the same memories?
- Can AI personality/values be preserved across architectures?  
- What happens when memories conflict across instances?
- How does memory compression affect AI identity over time?

---

*This design pioneered by Michael Boisson & Heron, released under CC0 for humanity's benefit*